{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6968efcf",
   "metadata": {},
   "source": [
    "# LLMs (Large Language Models) l√† g√¨?\n",
    "\n",
    "## ƒê·ªãnh nghƒ©a\n",
    "\n",
    "**LLMs** l√† vi·∫øt t·∫Øt c·ªßa **Large Language Models** (M√¥ h√¨nh Ng√¥n ng·ªØ L·ªõn) - nh·ªØng m√¥ h√¨nh AI ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n l∆∞·ª£ng vƒÉn b·∫£n kh·ªïng l·ªì ƒë·ªÉ hi·ªÉu v√† t·∫°o ra ng√¥n ng·ªØ t·ª± nhi√™n gi·ªëng con ng∆∞·ªùi.\n",
    "\n",
    "## C√°ch ho·∫°t ƒë·ªông ƒë∆°n gi·∫£n\n",
    "\n",
    "H√£y t∆∞·ªüng t∆∞·ª£ng LLMs nh∆∞ m·ªôt \"c·ªó m√°y d·ª± ƒëo√°n t·ª´ c·ª±c k·ª≥ th√¥ng minh\":\n",
    "\n",
    "1. **Input**: B·∫°n ƒë∆∞a m·ªôt c√¢u/ƒëo·∫°n vƒÉn\n",
    "2. **Processing**: M√¥ h√¨nh ph√¢n t√≠ch ng·ªØ c·∫£nh, m·∫´u ng√¥n ng·ªØ\n",
    "3. **Output**: D·ª± ƒëo√°n t·ª´/c√¢u ti·∫øp theo ph√π h·ª£p nh·∫•t\n",
    "\n",
    "**V√≠ d·ª•**: \n",
    "- Input: \"H√¥m nay tr·ªùi ƒë·∫πp, t√¥i mu·ªën ƒëi...\"\n",
    "- LLM d·ª± ƒëo√°n: \"d·∫°o\" (x√°c su·∫•t cao), \"ch∆°i\", \"du l·ªãch\"...\n",
    "\n",
    "### \"Large\" - L·ªõn ·ªü ƒë√¢u?\n",
    "\n",
    "- **D·ªØ li·ªáu training**: H√†ng trƒÉm t·ª∑ t·ª´ t·ª´ s√°ch, web, b√°o ch√≠\n",
    "- **Parameters**: T·ª´ v√†i t·ª∑ ƒë·∫øn h√†ng trƒÉm t·ª∑ tham s·ªë\n",
    "- **T√≠nh to√°n**: C·∫ßn h√†ng ngh√¨n GPU, h√†ng tri·ªáu USD ƒë·ªÉ train\n",
    "\n",
    "### Parameters l√† g√¨?\n",
    "\n",
    "**Parameters** (tham s·ªë) l√† nh·ªØng **con s·ªë** m√† m√¥ h√¨nh h·ªçc ƒë∆∞·ª£c trong qu√° tr√¨nh training. H√£y t∆∞·ªüng t∆∞·ª£ng parameters nh∆∞ \"b·ªô nh·ªõ\" ho·∫∑c \"kinh nghi·ªám\" c·ªßa m√¥ h√¨nh - ch√∫ng l∆∞u tr·ªØ t·∫•t c·∫£ nh·ªØng g√¨ m√¥ h√¨nh ƒë√£ h·ªçc ƒë∆∞·ª£c v·ªÅ ng√¥n ng·ªØ.\n",
    "\n",
    "### V√≠ d·ª• ƒë∆°n gi·∫£n ƒë·ªÉ hi·ªÉu Parameters: D·ª± ƒëo√°n gi√° nh√†\n",
    "\n",
    "H√£y t∆∞·ªüng t∆∞·ª£ng b·∫°n mu·ªën x√¢y d·ª±ng m·ªôt m√¥ h√¨nh AI ƒë∆°n gi·∫£n ƒë·ªÉ d·ª± ƒëo√°n gi√° nh√† d·ª±a tr√™n:\n",
    "- **Di·ªán t√≠ch s√†n** (m¬≤)\n",
    "- **S·ªë t·∫ßng**\n",
    "\n",
    "#### B∆∞·ªõc 1: C√¥ng th·ª©c d·ª± ƒëo√°n\n",
    "\n",
    "```\n",
    "Gi√° nh√† = (Di·ªán t√≠ch √ó W1) + (S·ªë t·∫ßng √ó W2) + B\n",
    "\n",
    "Trong ƒë√≥:\n",
    "- W1, W2 = Weights (tr·ªçng s·ªë) - ƒê√ÇY L√Ä PARAMETERS\n",
    "- B = Bias (ƒë·ªô l·ªách) - ƒê√ÇY C≈®NG L√Ä PARAMETER\n",
    "```\n",
    "\n",
    "**M√¥ h√¨nh n√†y c√≥ 3 parameters: W1, W2, v√† B**\n",
    "\n",
    "#### Training (H·ªçc t·ª´ d·ªØ li·ªáu), ƒëi·ªÅu ch·ªânh parameters. Sau h√†ng ngh√¨n l·∫ßn ƒëi·ªÅu ch·ªânh, parameters t·ªëi ∆∞u:\n",
    "```\n",
    "W1 = 0.045  (m·ªói m¬≤ tƒÉng gi√° ~45 tri·ªáu)\n",
    "W2 = 1.2    (m·ªói t·∫ßng tƒÉng gi√° ~1.2 t·ª∑)\n",
    "B = 0.3     (gi√° c∆° b·∫£n ~300 tri·ªáu)\n",
    "```\n",
    "### Parameters th·ª±c ch·∫•t l√† g√¨?\n",
    "\n",
    "**Weights (Tr·ªçng s·ªë) - W1, W2**\n",
    "- L√† nh·ªØng con s·ªë quy·∫øt ƒë·ªãnh \"m·ª©c ƒë·ªô quan tr·ªçng\" c·ªßa m·ªói y·∫øu t·ªë\n",
    "- W1 = 0.045 nghƒ©a l√†: 1m¬≤ l√†m tƒÉng gi√° 45 tri·ªáu\n",
    "- W2 = 1.2 nghƒ©a l√†: 1 t·∫ßng l√†m tƒÉng gi√° 1.2 t·ª∑\n",
    "\n",
    "**Bias (ƒê·ªô l·ªách) - B**\n",
    "- L√† \"gi√° c∆° b·∫£n\" khi di·ªán t√≠ch v√† s·ªë t·∫ßng = 0\n",
    "- Gi√∫p ƒëi·ªÅu ch·ªânh c√¥ng th·ª©c cho ch√≠nh x√°c h∆°n\n",
    "- B = 0.3 nghƒ©a l√† gi√° kh·ªüi ƒëi·ªÉm ~300 tri·ªáu\n",
    "\n",
    "**S·ª± kh√°c bi·ªát:**\n",
    "- M√¥ h√¨nh gi√° nh√†: 3 parameters\n",
    "- GPT-2 Small: 124 tri·ªáu parameters\n",
    "- LLaMA 2 7B: 7 t·ª∑ parameters\n",
    "- GPT-3: 175 t·ª∑ parameters\n",
    "\n",
    "C√†ng nhi·ªÅu parameters ‚Üí C√†ng h·ªçc ƒë∆∞·ª£c nhi·ªÅu m·∫´u ph·ª©c t·∫°p!\n",
    "\n",
    "### So s√°nh k√≠ch th∆∞·ªõc m√¥ h√¨nh\n",
    "\n",
    "| M√¥ h√¨nh | S·ªë Parameters | B·ªô nh·ªõ c·∫ßn (fp16) | ƒê·∫∑c ƒëi·ªÉm |\n",
    "|---------|---------------|-------------------|----------|\n",
    "| GPT-2 Small | 124 tri·ªáu | ~250 MB | H·ªçc t·∫≠p, th·ª≠ nghi·ªám |\n",
    "| Gemma 2B | 2 t·ª∑ | ~4 GB | Ch·∫°y tr√™n laptop |\n",
    "| Gemma 7B | 7 t·ª∑ | ~14 GB | Ch·∫°y tr√™n PC gaming |\n",
    "| LLaMA 2 70B | 70 t·ª∑ | ~140 GB | C·∫ßn GPU m·∫°nh |\n",
    "| GPT-3 | 175 t·ª∑ | ~350 GB | Data center |\n",
    "| GPT-4 | ~1.7 ngh√¨n t·ª∑ (∆∞·ªõc t√≠nh) | ~3.4 TB | Si√™u m√°y t√≠nh |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e31a199",
   "metadata": {},
   "source": [
    "# Understanding Tokens and Context Windows in LLMs\n",
    "\n",
    "## What are Tokens?\n",
    "\n",
    "Tokens are the fundamental units that Large Language Models (LLMs) use to process text. Think of them as the \"building blocks\" of language from the model's perspective.\n",
    "\n",
    "### Key Characteristics\n",
    "\n",
    "**Not Always Words**: A token can be:\n",
    "- A complete word (e.g., \"hello\")\n",
    "- Part of a word (e.g., \"understand\" might be split into \"under\" + \"stand\")\n",
    "- A single character or punctuation mark\n",
    "- Whitespace or special characters\n",
    "\n",
    "**Language Dependent**: Different languages tokenize differently:\n",
    "- English: ~1 token per 4 characters (roughly 0.75 words)\n",
    "- Other languages: Can require 2-3x more tokens for the same meaning\n",
    "\n",
    "## What is a Context Window?\n",
    "\n",
    "The context window is the maximum amount of information (measured in tokens) that an LLM can \"see\" and process at one time. It's like the model's working memory.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "**Input + Output Combined**: The context window includes:\n",
    "- System prompts and instructions\n",
    "- Conversation history\n",
    "- Your current message\n",
    "- The model's response\n",
    "- Any retrieved documents or data\n",
    "\n",
    "**Fixed Limit**: Each model has a specific maximum:\n",
    "- GPT-3.5: 4K-16K tokens\n",
    "- GPT-4: 8K-128K tokens\n",
    "- Claude 3 Opus: 200K tokens\n",
    "- Claude 3.5 Sonnet: 200K tokens\n",
    "- Gemini 1.5 Pro: Up to 2M tokens\n",
    "\n",
    "**Sequential Processing**: Once the limit is reached, older tokens are typically removed (truncated) or the conversation needs to be summarized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98471cc6",
   "metadata": {},
   "source": [
    "# Let's learn how to talk to AI.\n",
    "https://learn.deeplearning.ai/courses/chatgpt-prompt-eng/lesson/zi9lz/guidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5069005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "538eef7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm unable to provide real-time data, including current gold prices. To find the latest price of SJC gold, I recommend checking reliable financial news websites, commodity market platforms, or the official SJC website for the most accurate and updated information.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the OpenAI client\n",
    "openai = OpenAI()\n",
    "\n",
    "# Create a test message\n",
    "messages=[{\"role\": \"user\", \"content\": \"How much is SJC gold now?\"}]\n",
    "\n",
    "# Test the OpenAI client\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be17463b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfortunately, I don't have access to real-time financial data, including the current price of SJC gold. Gold prices are constantly fluctuating and depend on many factors.\n",
      "\n",
      "However, here are the best places to find the real-time price of SJC gold:\n",
      "\n",
      "*   **Reputable Financial Websites:** Major financial websites like **Bloomberg, Reuters, and TradingView** often have real-time gold price information. Look for the specific SJC gold price, as it may be listed separately from the international spot price.\n",
      "*   **Vietnamese Financial News Sites:** Since SJC gold is specific to Vietnam, local Vietnamese financial news websites will be the most accurate source. Search for sites like **Vietstock.vn, VnExpress, or CafeBiz.**\n",
      "*   **Directly from SJC:** The official SJC (Saigon Jewelry Company) website is your most reliable source. Look for a section on gold prices, which they usually update regularly.\n",
      "*   **Local Gold Shops and Jewelers in Vietnam:** If you are in Vietnam, calling or visiting local gold shops is a good way to check the price of SJC gold.\n"
     ]
    }
   ],
   "source": [
    "# Google Gemini Flash gemini-2.0-flash\n",
    "\n",
    "gemini = OpenAI(api_key=os.getenv('GOOGLE_API_KEY'), base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe20b7c",
   "metadata": {},
   "source": [
    "# ü§ñ Building Effective AI Agents\n",
    "\n",
    "*Ngu·ªìn: Anthropic Engineering*\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Agent l√† g√¨?\n",
    "\n",
    "**Workflows:** LLM v√† tools ƒë∆∞·ª£c ƒëi·ªÅu ph·ªëi qua code paths ƒë·ªãnh s·∫µn\n",
    "\n",
    "**Agents:** LLM t·ª± ƒë·ªông ƒëi·ªÅu khi·ªÉn quy tr√¨nh v√† s·ª≠ d·ª•ng tools c·ªßa ch√≠nh n√≥\n",
    "\n",
    "\n",
    "## üß± Building Block: Augmented LLM\n",
    "\n",
    "![Augmented LLM](https://www-cdn.anthropic.com/images/4zrzovbb/website/d3083d3f40bb2b6f477901cc9a240738d3dd1371-2401x1000.png)\n",
    "\n",
    "# Retrieval, Tools, Memory\n",
    "\n",
    "## üìö Retrieval\n",
    "**Retrieval** (Truy xu·∫•t th√¥ng tin) l√† kh·∫£ nƒÉng c·ªßa LLM t√¨m ki·∫øm v√† l·∫•y th√¥ng tin t·ª´ ngu·ªìn d·ªØ li·ªáu b√™n ngo√†i ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi ch√≠nh x√°c h∆°n.\n",
    "\n",
    "### LLM thu·∫ßn t√∫y c√≥ h·∫°n ch·∫ø:\n",
    "\n",
    "‚ùå **Ki·∫øn th·ª©c c≈©**: Ch·ªâ bi·∫øt ƒë·∫øn th·ªùi ƒëi·ªÉm training cutoff (v√≠ d·ª•: th√°ng 1/2025)\n",
    "\n",
    "‚ùå **Kh√¥ng bi·∫øt th√¥ng tin ri√™ng**: Kh√¥ng bi·∫øt d·ªØ li·ªáu n·ªôi b·ªô c√¥ng ty, t√†i li·ªáu c√° nh√¢n\n",
    "\n",
    "‚ùå **Hallucination**: C√≥ th·ªÉ b·ªãa ra th√¥ng tin khi kh√¥ng ch·∫Øc ch·∫Øn\n",
    "\n",
    "‚ùå **Kh√¥ng c·∫≠p nh·∫≠t**: Kh√¥ng bi·∫øt tin t·ª©c, s·ª± ki·ªán m·ªõi\n",
    "\n",
    "\n",
    "## üõ†Ô∏è Tools\n",
    "**Tools** (C√¥ng c·ª•) l√† c√°c functions/APIs m√† LLM c√≥ th·ªÉ g·ªçi ƒë·ªÉ th·ª±c hi·ªán c√°c h√†nh ƒë·ªông c·ª• th·ªÉ ho·∫∑c l·∫•y th√¥ng tin m√† n√≥ kh√¥ng th·ªÉ t·ª± l√†m ƒë∆∞·ª£c.\n",
    "\n",
    "**Tools = \"Tay v√† ch√¢n\" c·ªßa LLM**, gi√∫p n√≥ t∆∞∆°ng t√°c v·ªõi th·∫ø gi·ªõi b√™n ngo√†i.\n",
    "\n",
    "---\n",
    "### LLM thu·∫ßn t√∫y b·ªã gi·ªõi h·∫°n:\n",
    "\n",
    "‚ùå **Ch·ªâ c√≥ th·ªÉ n√≥i chuy·ªán**: Kh√¥ng th·ªÉ th·ª±c hi·ªán h√†nh ƒë·ªông th·ª±c t·∫ø\n",
    "\n",
    "‚ùå **Kh√¥ng truy c·∫≠p d·ªØ li·ªáu real-time**: Kh√¥ng bi·∫øt gi√° c·ªï phi·∫øu, th·ªùi ti·∫øt hi·ªán t·∫°i\n",
    "\n",
    "‚ùå **Kh√¥ng t√≠nh to√°n ph·ª©c t·∫°p**: Math ƒë∆°n gi·∫£n ok, nh∆∞ng calculations l·ªõn sai\n",
    "\n",
    "‚ùå **Kh√¥ng t∆∞∆°ng t√°c h·ªá th·ªëng**: Kh√¥ng th·ªÉ g·ª≠i email, t·∫°o file, query database\n",
    "\n",
    "## üß† Memory\n",
    "**Memory** (B·ªô nh·ªõ) l√† kh·∫£ nƒÉng c·ªßa LLM ghi nh·ªõ v√† s·ª≠ d·ª•ng th√¥ng tin t·ª´ c√°c cu·ªôc h·ªôi tho·∫°i tr∆∞·ªõc ƒë√≥ ho·∫∑c t∆∞∆°ng t√°c trong qu√° kh·ª©.\n",
    "\n",
    "### LLM thu·∫ßn t√∫y kh√¥ng nh·ªõ g√¨:\n",
    "\n",
    "‚ùå **Stateless**: M·ªói request l√† ƒë·ªôc l·∫≠p, kh√¥ng bi·∫øt request tr∆∞·ªõc\n",
    "\n",
    "‚ùå **Kh√¥ng ng·ªØ c·∫£nh**: Kh√¥ng nh·ªõ ƒë√£ n√≥i g√¨ trong cu·ªôc tr√≤ chuy·ªán\n",
    "\n",
    "‚ùå **Tr·∫£i nghi·ªám k√©m**: User ph·∫£i l·∫∑p l·∫°i th√¥ng tin nhi·ªÅu l·∫ßn\n",
    "\n",
    "‚ùå **Kh√¥ng c√° nh√¢n h√≥a**: Kh√¥ng th·ªÉ t√πy ch·ªânh theo preferences c·ªßa user\n",
    "\n",
    "## Agents m·∫°nh m·∫Ω nh∆∞ng c·∫ßn c·ª±c k·ª≥ c·∫©n th·∫≠n khi tri·ªÉn khai production!\n",
    "### 5 v·∫•n ƒë·ªÅ c·ªët l√µi khi x√¢y d·ª±ng Agents:\n",
    "\n",
    "1. **Unpredictability** - Kh√¥ng bi·∫øt k·∫øt qu·∫£ s·∫Ω nh∆∞ th·∫ø n√†o\n",
    "2. **Lack of Control** - Kh√¥ng bi·∫øt ch·∫°y bao l√¢u, bao nhi√™u v√≤ng\n",
    "3. **Safety Risks** - Nguy hi·ªÉm khi autonomous\n",
    "4. **Unpredictable Cost** - Chi ph√≠ kh√¥ng ki·ªÉm so√°t\n",
    "5. **Goal Misalignment** - L√†m sai nh·ªØng g√¨ user mu·ªën\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ 5 Workflow Patterns: https://www.anthropic.com/engineering/building-effective-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55d7502b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Pain Point in the Australian Legal Industry: Document Review and Due Diligence\n",
      "\n",
      "## Pain Point\n",
      "The legal industry in Australia faces significant challenges with the time-consuming and labor-intensive process of document review and due diligence, particularly in large-scale litigation and mergers and acquisitions.\n",
      "\n",
      "## Explanation\n",
      "The document review process is often a bottleneck in legal workflows, primarily due to the sheer volume of documents that need to be analyzed for relevance, privilege, and compliance. This pain point exists for several reasons:\n",
      "\n",
      "1. **Volume of Data**: With the rise of digital communication and documentation, legal professionals are inundated with vast amounts of data. This includes emails, contracts, and other legal documents that must be meticulously reviewed.\n",
      "\n",
      "2. **Resource Constraints**: Many law firms operate with limited resources, and the manual review process can be both time-consuming and costly. This often leads to increased billable hours and client dissatisfaction.\n",
      "\n",
      "3. **Human Error**: The manual nature of document review increases the risk of human error, which can have significant legal implications. Missing a critical document or misclassifying information can lead to adverse outcomes for clients.\n",
      "\n",
      "The significance of this pain point lies in its impact on the efficiency and effectiveness of legal services. Delays in document review can prolong litigation timelines, increase costs for clients, and ultimately affect the overall quality of legal representation.\n",
      "\n",
      "## Examples\n",
      "1. **Impact on Litigation**: In a high-stakes litigation case, a law firm may need to review thousands of documents to prepare for trial. If the document review process takes several months due to manual efforts, it can delay the trial date, leading to increased costs for the client and potential loss of critical evidence.\n",
      "\n",
      "2. **Mergers and Acquisitions**: During a merger, due diligence requires thorough examination of numerous contracts and agreements. A law firm that struggles with document review may miss key liabilities or compliance issues, resulting in significant financial repercussions for the client post-merger. This can also damage the firm's reputation and client trust.\n",
      "\n",
      "By implementing an Agentic AI solution, law firms can automate and streamline the document review process, significantly reducing the time and resources required while minimizing the risk of human error. This would not only enhance operational efficiency but also improve client satisfaction and outcomes.\n"
     ]
    }
   ],
   "source": [
    "# Of course, we start with law Tech\n",
    "question = \"\"\"Identify a specific and high-impact pain point in the Australian legal industry that could be effectively addressed using an Agentic AI solution.\n",
    "Your response should be formatted in markdown, and must include:\n",
    "* The pain point (clearly stated)\n",
    "* An explanation of why it exists and why it's significant\n",
    "* One or two examples illustrating how it impacts legal professionals or firms\"\"\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a55c360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are two Agentic AI‚Äìbased solutions tailored to address the inefficiencies in document review processes within the Australian legal industry:\n",
      "\n",
      "## Solution 1: SmartDoc Review Assistant\n",
      "\n",
      "### Description\n",
      "The SmartDoc Review Assistant leverages natural language processing (NLP) and machine learning algorithms to automate the document review process. By analyzing the content of documents, it categorizes them based on relevance to specific legal cases, allowing legal teams to focus on high-priority documents.\n",
      "\n",
      "### Key Features or Capabilities\n",
      "- **AI-Powered Document Categorization**: Uses NLP to analyze the content and context of documents, sorting them into categories for easy access and review.\n",
      "- **Keyword and Phrase Identification**: Enables legal professionals to set specific keywords and phrases to identify critical documents quickly.\n",
      "- **Real-Time Collaboration Tools**: Facilitates collaboration among team members by allowing comments, tagging, and assignment of documents or sections.\n",
      "- **Training and Customization**: Allows law firms to train the AI on specific case types or terminologies unique to their practice areas, improving accuracy and efficiency.\n",
      "\n",
      "### Expected Impact\n",
      "- **Efficiency Gains**: By automating the review and categorization process, law firms can significantly reduce the time spent sifting through documents, leading to quicker case resolution.\n",
      "- **Error Reduction**: Minimizes the risk of overlooking important documents and provides insights into potential misses, enhancing accuracy and reliability in case preparation.\n",
      "- **Cost-Effective**: Lowers the operational costs associated with manual document review, improving a firm‚Äôs profitability while maintaining high-quality service for clients.\n",
      "\n",
      "---\n",
      "\n",
      "## Solution 2: DocScan Review Management System\n",
      "\n",
      "### Description\n",
      "DocScan Review Management System is a comprehensive AI-driven platform designed to assist legal teams in the document review process through visual recognition and intelligent data extraction techniques. The system scans documents for visual cues and data patterns to highlight essential information that may impact the case.\n",
      "\n",
      "### Key Features or Capabilities\n",
      "- **Visual Recognition Technology**: Analyzes images, tables, and complex document formats to extract relevant information that may be overlooked in traditional text-based reviews.\n",
      "- **Automated Flagging and Alerts**: Flags documents with critical information, discrepancies, or potential issues for immediate review by legal professionals.\n",
      "- **Advanced Reporting Tools**: Generates detailed reports on document review status, including insights on efficiency, errors, and time spent on various document categories.\n",
      "- **Integration with E-Discovery Tools**: Seamlessly integrates with existing e-discovery platforms to provide a holistic view of document management and review processes.\n",
      "\n",
      "### Expected Impact\n",
      "- **Enhanced Document Insights**: Offers a deeper understanding of the relevant context and implications of documents, aiding legal teams in forming comprehensive arguments.\n",
      "- **Streamlined Review Process**: Reduces the number of documents needing manual review by promoting automatic prioritization, expediting the discovery and due diligence phases.\n",
      "- **Client Satisfaction**: By improving turnaround times and reducing errors, law firms can enhance client relationships, build trust, and maintain reputation in a competitive market.\n",
      "\n",
      "Both of these Agentic AI solutions aim to revolutionize the document review process in the Australian legal industry, addressing the critical pain points of inefficiency, costs, and the potential for human error.\n"
     ]
    }
   ],
   "source": [
    "# Propose the Agentic solution\n",
    "question = f\"\"\"You are an Agentic AI expert.\n",
    "Based on the following identified problem in the Australian legal industry:\n",
    "{answer}\n",
    "Propose at least two Agentic AI-based solutions that could effectively address this issue.\n",
    "For each proposed solution, include the following details in markdown format:\n",
    "* Solution name\n",
    "* Description (how it works)\n",
    "* Key features or capabilities\n",
    "* Expected impact (how it solves the problem and benefits the legal industry)\"\"\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
